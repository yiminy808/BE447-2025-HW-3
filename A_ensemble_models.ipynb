{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook A: Ensemble Models\n",
        "\n",
        "Use this notebook to go through the process of using ensemble models to predict heart disease. Load the [Cleveland heart disease dataset](https://archive.ics.uci.edu/dataset/45/heart+disease), preprocess the data, perform a train-test split, and use a grid search to find the best parameters for a bagging classifier and an adaboost classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleveland_df = pd.read_csv('cleveland_heart_disease.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert not cleveland_df.empty, \"DataFrame is empty\"\n",
        "assert cleveland_df.shape == (303, 14), \"DataFrame has incorrect number of columns\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Proprocess data\n",
        "Remove the rows that have question marks in them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleveland_df = cleveland_df[~df.apply(lambda row: row.astype(str).str.contains(r\"\\?\").any(), axis=1)].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert cleveland_df.shape == (297, 14), \"DataFrame has incorrect number of columns\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['age', 'gender', 'cp', 'trestbps', 'chol', 'fps', 'restecg', 'thalach',\n",
            "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'class'],\n",
            "      dtype='object')\n",
            "   age  gender  cp  trestbps  chol  fps  restecg  thalach  exang  oldpeak  \\\n",
            "0   63       1   1       145   233    1        2      150      0      2.3   \n",
            "1   67       1   4       160   286    0        2      108      1      1.5   \n",
            "2   67       1   4       120   229    0        2      129      1      2.6   \n",
            "3   37       1   3       130   250    0        0      187      0      3.5   \n",
            "4   41       0   2       130   204    0        2      172      0      1.4   \n",
            "\n",
            "   slope ca thal  class  \n",
            "0      3  0    6      0  \n",
            "1      2  3    3      2  \n",
            "2      2  2    7      1  \n",
            "3      3  0    3      0  \n",
            "4      1  0    3      0  \n"
          ]
        }
      ],
      "source": [
        "print(cleveland_df.columns)\n",
        "print(cleveland_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train-Test Split\n",
        "Use 80% of the data for training data, and set the random state to 42."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "cleveland_df [\"class\"] = cleveland_df[\"class\"].apply(lambda x: 1 if x > 0 else 0)\n",
        "X = cleveland_df.drop(columns=[\"class\"])  \n",
        "y = cleveland_df[\"class\"]  \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure that the split was successful\n",
        "assert X_train.shape[0] > 0 and X_test.shape[0] > 0, \"Something went wrong in train-test split.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bagging Model Training\n",
        "First, define a bagging classifier that uses KNeighbors classifier as the base estimator, and has random_state=42.\n",
        "\n",
        "Then, use a grid search, with five fold cross validation, to find the best parameters for the bagging classifier.\n",
        "\n",
        "Use accuracy for scoring the parameter combinations, and use this parameter grid:\n",
        "\n",
        "```python\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_samples': [0.5, 0.75, 1.0], \n",
        "    'max_features': [0.5, 0.75, 1.0] \n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 50} 0.7590425531914894\n"
          ]
        }
      ],
      "source": [
        "# define the base estimator\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# define the BaggingClassifier with KNN as the base estimator\n",
        "bagging_clf = BaggingClassifier(estimator=knn, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_samples': [0.5, 0.75, 1.0], \n",
        "    'max_features': [0.5, 0.75, 1.0]\n",
        "}\n",
        "\n",
        "bagging_grid_search = GridSearchCV(\n",
        "    estimator=bagging_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5, # 5-fold cross-validation\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "bagging_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(bagging_grid_search.best_params_, bagging_grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Incorrect best score",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m bagging_grid_search.best_params_ == {\u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.5\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.5\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m50\u001b[39m}, \u001b[33m\"\u001b[39m\u001b[33mIncorrect best parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m bagging_grid_search.best_score_ > \u001b[32m0.560\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m bagging_grid_search.best_score_ < \u001b[32m0.561\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mIncorrect best score\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: Incorrect best score"
          ]
        }
      ],
      "source": [
        "assert bagging_grid_search.best_params_ == {'max_features': 0.5, 'max_samples': 0.75, 'n_estimators': 50}, \"Incorrect best parameters\"\n",
        "assert bagging_grid_search.best_score_ > 0.560 and bagging_grid_search.best_score_ < 0.561, \"Incorrect best score\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### It seems like my model is too good?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AdaBoost Model Training\n",
        "First, define a adaboost classifier that uses the decision tree classifier as the base estimator (the default behavior), and has random_state=42.\n",
        "\n",
        "Then, use a grid search, with five fold cross validation, to find the best parameters for the adaboost classifier. \n",
        "\n",
        "Use this parameter grid:\n",
        "\n",
        "```python\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "```\n",
        "\n",
        "There may be warnings. You can ignore these.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.1, 'n_estimators': 100} 0.8185283687943261\n"
          ]
        }
      ],
      "source": [
        "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "ada_grid_search = GridSearchCV(\n",
        "    estimator=adaboost_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "ada_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(ada_grid_search.best_params_, ada_grid_search.best_score_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Incorrect best parameters",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m ada_grid_search.best_params_ == {\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.01\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m100\u001b[39m}, \u001b[33m\"\u001b[39m\u001b[33mIncorrect best parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m ada_grid_search.best_score_ > \u001b[32m0.579\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ada_grid_search.best_score_ < \u001b[32m0.580\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mIncorrect best score\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: Incorrect best parameters"
          ]
        }
      ],
      "source": [
        "assert ada_grid_search.best_params_ == {'learning_rate': 0.01, 'n_estimators': 100}, \"Incorrect best parameters\"\n",
        "assert ada_grid_search.best_score_ > 0.579 and ada_grid_search.best_score_ < 0.580, \"Incorrect best score\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same error as the last test\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
